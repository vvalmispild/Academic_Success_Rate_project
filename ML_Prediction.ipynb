{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction student's dropout and academic success "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim to create a machine learning algorithm that can anticipate a student's academic progress after the first semester, with a particular emphasis on forecasting whether they will successfully complete the course or withdraw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 100\n",
    "import warnings \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Data\n",
    "df = pd.read_csv(\"./dataset.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"Enrolled\" values will not be used in the model\n",
    "df = df[df.Target != \"Enrolled\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "df = df.rename(columns= {'Marital status': 'Marital_Status',\n",
    "                    'Application mode': 'Application_Mode',\n",
    "                    'Application order': 'Application_Order',\n",
    "                    'Daytime/evening attendance': 'Day_Ev_Attend',\n",
    "                    'Previous qualification': 'Previous_Qualification',\n",
    "                    'Nacionality': 'Nationality',\n",
    "                    \"Mother's qualification\": 'Mother_Qualification',\n",
    "                    \"Father's qualification\": 'Father_Qualification',\n",
    "                    \"Mother's occupation\": 'Mother_Occupation',\n",
    "                    \"Father's occupation\": 'Father_Occupation',\n",
    "                    'Educational special needs': 'Special_Needs',\n",
    "                    'Tuition fees up to date': 'Tuition_Fees',\n",
    "                    'Scholarship holder': 'Scholarship',\n",
    "                    'Age at enrollment': 'Enrollment_Age',\n",
    "                    'Curricular units 1st sem (credited)': 'CU_1st_Credited',\n",
    "                    'Curricular units 1st sem (enrolled)': 'CU_1st_Enrolled',\n",
    "                    'Curricular units 1st sem (evaluations)': 'CU_1st_Evaluations',\n",
    "                    'Curricular units 1st sem (approved)': 'CU_1st_Approved',\n",
    "                    'Curricular units 1st sem (grade)': 'CU_1st_Grade',\n",
    "                    'Curricular units 1st sem (without evaluations)': 'CU_1st_NoEvaluations',\n",
    "                    'Curricular units 2nd sem (credited)': 'CU_2nd_Credited',\n",
    "                    'Curricular units 2nd sem (enrolled)': 'CU_2nd_Enrolled',\n",
    "                    'Curricular units 2nd sem (evaluations)': 'CU_2nd_Evaluations',\n",
    "                    'Curricular units 2nd sem (approved)': 'CU_2nd_Approved',\n",
    "                    'Curricular units 2nd sem (grade)': 'CU_2nd_Grade',\n",
    "                    'Curricular units 2nd sem (without evaluations)': 'CU_2nd_NoEvaluations',\n",
    "                    'Unemployment rate': 'Unemploymen_Rate',\n",
    "                    'Inflation rate': 'Inflation_Rate',\n",
    "                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Target'] = df['Target'].map({'Dropout':0, 'Graduate':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Marital_Status           -0.100479\n",
       "Application_Mode         -0.233888\n",
       "Application_Order         0.094355\n",
       "Course                    0.006814\n",
       "Day_Ev_Attend             0.084496\n",
       "Previous_Qualification   -0.102795\n",
       "Nationality              -0.003823\n",
       "Mother_Qualification     -0.048459\n",
       "Father_Qualification     -0.003850\n",
       "Mother_Occupation         0.064195\n",
       "Father_Occupation         0.073238\n",
       "Displaced                 0.126113\n",
       "Special_Needs            -0.007254\n",
       "Debtor                   -0.267207\n",
       "Tuition_Fees              0.442138\n",
       "Gender                   -0.251955\n",
       "Scholarship               0.313018\n",
       "Enrollment_Age           -0.267229\n",
       "International             0.006181\n",
       "CU_1st_Credited           0.046900\n",
       "CU_1st_Enrolled           0.161074\n",
       "CU_1st_Evaluations        0.059786\n",
       "CU_1st_Approved           0.554881\n",
       "CU_1st_Grade              0.519927\n",
       "CU_1st_NoEvaluations     -0.074642\n",
       "CU_2nd_Credited           0.052402\n",
       "CU_2nd_Enrolled           0.182897\n",
       "CU_2nd_Evaluations        0.119239\n",
       "CU_2nd_Approved           0.653995\n",
       "CU_2nd_Grade              0.605350\n",
       "CU_2nd_NoEvaluations     -0.102687\n",
       "Unemploymen_Rate          0.004198\n",
       "Inflation_Rate           -0.030326\n",
       "GDP                       0.050260\n",
       "Target                    1.000000\n",
       "Name: Target, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looking at the corelation, we need to select the required columns for prediction.\n",
    "df.corr()['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Marital_Status', 'Application_Mode', 'Application_Order', 'Course',\n",
       "       'Day_Ev_Attend', 'Previous_Qualification', 'Nationality',\n",
       "       'Mother_Qualification', 'Father_Qualification', 'Mother_Occupation',\n",
       "       'Father_Occupation', 'Displaced', 'Special_Needs', 'Debtor',\n",
       "       'Tuition_Fees', 'Gender', 'Scholarship', 'Enrollment_Age',\n",
       "       'International', 'CU_1st_Credited', 'CU_1st_Enrolled',\n",
       "       'CU_1st_Evaluations', 'CU_1st_Approved', 'CU_1st_Grade',\n",
       "       'CU_1st_NoEvaluations', 'CU_2nd_Credited', 'CU_2nd_Enrolled',\n",
       "       'CU_2nd_Evaluations', 'CU_2nd_Approved', 'CU_2nd_Grade',\n",
       "       'CU_2nd_NoEvaluations', 'Unemploymen_Rate', 'Inflation_Rate', 'GDP',\n",
       "       'Target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of data for machine learning, taking into account multicorrelation from EDA and the goal of the project\n",
    "df = df[[#'Marital_Status', \n",
    "         'Application_Mode', \n",
    "         #'Application_Order', \n",
    "         #'Course', \n",
    "         #'Day_Ev_Attend', \n",
    "         'Previous_Qualification', \n",
    "         #'Nationality',\n",
    "         #'Mother_Qualification', \n",
    "         #'Father_Qualification', \n",
    "         #'Mother_Occupation', 'Father_Occupation', 'Displaced', \n",
    "         #'Special_Needs', \n",
    "         'Debtor',\n",
    "         'Tuition_Fees', \n",
    "         'Gender', \n",
    "         'Scholarship', \n",
    "         'Enrollment_Age',\n",
    "         #'International', \n",
    "         #'CU_1st_Credited', \n",
    "         #'CU_1st_Enrolled', \n",
    "         #'CU_1st_Evaluations', \n",
    "         'CU_1st_Approved', \n",
    "         #'CU_1st_Grade',\n",
    "         #'CU_1st_NoEvaluations', \n",
    "         #'CU_2nd_Credited', 'CU_2nd_Enrolled',\n",
    "         #'CU_2nd_Evaluations', 'CU_2nd_Approved', 'CU_2nd_Grade',\n",
    "         #'CU_2nd_NoEvaluations', \n",
    "         #'Unemploymen_Rate', 'Inflation_Rate', 'GDP',\n",
    "        'Target']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3630, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting independent and dependent variables\n",
    "X = df.drop(\"Target\", axis=1)\n",
    "y = df.Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_tester(model_dict, X, y, cv=5):    \n",
    "    scoring_param = [\"accuracy\", \"precision\", \"recall\", \"f1_micro\", \"f1_macro\"]\n",
    "    cv_score = {} # To append Scores of each Model\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(42)\n",
    "    for name, model in tqdm(model_dict.items()):\n",
    "        # enumerating through All Models in Dictionery\n",
    "        cv_score[name] = {}\n",
    "        for param in scoring_param:\n",
    "            # Calculating Mean values for cross validation with each Parameter\n",
    "            score = np.mean(cross_val_score(model, X, y, scoring=param, cv=cv))\n",
    "            cv_score[name][param] = score \n",
    "    cv = pd.DataFrame(data=cv_score)\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd2a1cc7e544104bdf009f481737cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistc Regression</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Balanced Random Forest</th>\n",
       "      <th>KNN</th>\n",
       "      <th>SVM</th>\n",
       "      <th>XGBOOST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.860606</td>\n",
       "      <td>0.846281</td>\n",
       "      <td>0.841873</td>\n",
       "      <td>0.831680</td>\n",
       "      <td>0.841598</td>\n",
       "      <td>0.851240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.858474</td>\n",
       "      <td>0.854389</td>\n",
       "      <td>0.873773</td>\n",
       "      <td>0.831427</td>\n",
       "      <td>0.824737</td>\n",
       "      <td>0.858500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.923704</td>\n",
       "      <td>0.910246</td>\n",
       "      <td>0.868328</td>\n",
       "      <td>0.907213</td>\n",
       "      <td>0.939163</td>\n",
       "      <td>0.904835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_micro</th>\n",
       "      <td>0.860606</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.841047</td>\n",
       "      <td>0.831680</td>\n",
       "      <td>0.841598</td>\n",
       "      <td>0.851240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.849770</td>\n",
       "      <td>0.838368</td>\n",
       "      <td>0.832926</td>\n",
       "      <td>0.817776</td>\n",
       "      <td>0.825529</td>\n",
       "      <td>0.841179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistc Regression  Random Forest  Balanced Random Forest  \\\n",
       "accuracy             0.860606       0.846281                0.841873   \n",
       "precision            0.858474       0.854389                0.873773   \n",
       "recall               0.923704       0.910246                0.868328   \n",
       "f1_micro             0.860606       0.848485                0.841047   \n",
       "f1_macro             0.849770       0.838368                0.832926   \n",
       "\n",
       "                KNN       SVM   XGBOOST  \n",
       "accuracy   0.831680  0.841598  0.851240  \n",
       "precision  0.831427  0.824737  0.858500  \n",
       "recall     0.907213  0.939163  0.904835  \n",
       "f1_micro   0.831680  0.841598  0.851240  \n",
       "f1_macro   0.817776  0.825529  0.841179  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = {'Logistc Regression' : LogisticRegression(),\n",
    "              'Random Forest' : RandomForestClassifier(),\n",
    "              'Balanced Random Forest' : BalancedRandomForestClassifier(),\n",
    "              'KNN' : KNeighborsClassifier(),\n",
    "              'SVM': SVC(),\n",
    "              'XGBOOST': XGBClassifier()}\n",
    "\n",
    "model_tester(model_dict, X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is the most optimal model. The next step is to tune this model by changing the model's hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=1, shuffle=True),\n",
       "             estimator=LogisticRegression(),\n",
       "             param_grid={'C': array([1.00000000e-04, 1.88739182e-04, 3.56224789e-04, 6.72335754e-04,\n",
       "       1.26896100e-03, 2.39502662e-03, 4.52035366e-03, 8.53167852e-03,\n",
       "       1.61026203e-02, 3.03919538e-02, 5.73615251e-02, 1.08263673e-01,\n",
       "       2.04335972e-01, 3.85662042e-01, 7.27895384e-01, 1.3738238...,\n",
       "       2.59294380e+00, 4.89390092e+00, 9.23670857e+00, 1.74332882e+01,\n",
       "       3.29034456e+01, 6.21016942e+01, 1.17210230e+02, 2.21221629e+02,\n",
       "       4.17531894e+02, 7.88046282e+02, 1.48735211e+03, 2.80721620e+03,\n",
       "       5.29831691e+03, 1.00000000e+04]),\n",
       "                         'class_weight': ['balanced', 'None'],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting grid for logistic regression parameters \n",
    "lr_grid = {\"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\n",
    "           \"penalty\" : [\"l1\", \"l2\", \"elasticnet\"],\n",
    "           \"C\" : np.logspace(-4, 4, 30),\n",
    "           \"class_weight\" : [\"balanced\", \"None\"]}\n",
    "\n",
    "gs_log_reg_model = GridSearchCV(LogisticRegression(),\n",
    "                                param_grid=lr_grid,\n",
    "                                cv=cv,\n",
    "                                verbose=1)\n",
    "gs_log_reg_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned hyperparameters for logistic regression: {'C': 4.893900918477489, 'class_weight': 'None', 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuned hyperparameters for logistic regression:\", gs_log_reg_model.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f35d28bd81d4695aaf5255b06b6aa25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.860882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.850110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_micro</th>\n",
       "      <td>0.860882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.858805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.923704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic Regression\n",
       "accuracy              0.860882\n",
       "f1_macro              0.850110\n",
       "f1_micro              0.860882\n",
       "precision             0.858805\n",
       "recall                0.923704"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the logistic regression model with tuned hyperparameters\n",
    "tuned_model_dict = {\"Logistic Regression\" : LogisticRegression(penalty='l2',\n",
    "                                                              solver='newton-cg',\n",
    "                                                              C=4.893900918477489)}\n",
    "model_tester(tuned_model_dict, X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model, in the form of a python object, was converted into a character stream using pickling. The purpose of this was to include all the information required to reconstruct the object in a different python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(gs_log_reg_model, open('model.p','wb'))\n",
    "model = pickle.load(open('model.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([[8, 1, 1, 1, 0, 0, 25, 6]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this file in our production application to estimate the success rate of a student by providing information about the student."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
